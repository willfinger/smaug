---
title: "MiniMax AI - Ollama Partnership"
type: tool
category: ai-ml
tags: ["ai-models", "partnership", "ollama", "llm", "cloud"]
priority: high
rating: 0
status: unread
date_added: 2026-02-13
stars: N/A
language: N/A
---
MiniMax AI and Ollama have announced a partnership to provide free access to MiniMax M2.5 model for Ollama users.

## Partnership Details

- **Free Access**: Ollama users get free usage of MiniMax M2.5 for the next couple of days
- **Model Integration**: MiniMax M2.5 is now available through ollama run command
- **Multiple Platform Support**: Works with OpenCode, Claude Code, Codex, and OpenClaw via ollama launch

## Usage Instructions

### Basic Usage
```bash
ollama run minimax-m2.5:cloud
```

### Integration with OpenCode
```bash
ollama launch opencode --model minimax-m2.5:cloud
```

### Integration with Claude
```bash
ollama launch claude --model minimax-m2.5:cloud
```

## Source
- Tweet: https://x.com/ollama/status/2022018134186791177
- Author: @ollama
- Date: Thursday, February 12, 2026

## Tags
- [[ai-models]]
- [[partnership]]
- [[ollama]]
- [[llm]]
- [[cloud]]